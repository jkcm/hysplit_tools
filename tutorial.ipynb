{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial for using HYSPLIT in Python\n",
    "\n",
    "For this tutorial, you must have previously installed [HYSPLIT](https://ready.arl.noaa.gov/HYSPLIT.php) on your machine. Much of the code here will write read/write files from/to disk. Disk locations are specified in config.py, along with the hysplit system call; edit these before use.\n",
    "\n",
    "We'll walk through a couple operations here to demonstrate how to use this code.\n",
    "\n",
    "1) Download some NCEP data,  \n",
    "2) run a single forecast trajectory, and run a grid of analysis trajectories,  \n",
    "3) plot a grid of trajectories (including reading trajectory files).\n",
    "\n",
    "If anything is unclear, either consult the HYSPLIT [user guide](https://www.arl.noaa.gov/documents/reports/hysplit_user_guide.pdf) or email jkcm@uw.edu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hysplit_utils as utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1: Downloading Data  \n",
    "HYSPLIT requires model data files to run locally. If you are using NCEP GFS (forecast) or GDAS (analysis) data, ARL (NOAA Air Resources Laboratory) provides these in a HYSPLIT-readable format [here](https://ready.arl.noaa.gov/HYSPLIT.php). If you wish to use e.g. ECMWF model data, they also provide conversion utilities. In this tutorial we will be using both GDAS and GFS forecast data for our trajectories.\n",
    "\n",
    "If you are running this code at UW and looking at past analysis (or, for whatever reason, past forecast data), much of the data from 07/2015-04/2018 (time or writing) already exists on our local system, found at /home/disk/eos4/jkcm/Data/HYSPLIT/source/analysis (or /forecast). As these datafiles are 500MB per day, it saves download time and storage space to use these files so please feel free to do so.  \n",
    "If you wish to use different data, or for different days, this package also contains code for downloading GDAS and GFS data directly from the ARL servers.\n",
    "\n",
    "Data download functions in hysplit_utils module (each function checks to see whether the target file has already been downloaded, and uses ftp to download if not):  \n",
    "**get_imagery:** download goestationary data from NASA SatCORPS, specified by satellite and date. This functionality works by the grace of the SatCORPS group, and breaks if they change naming or data availability.  \n",
    "**get_hysplit_analysis:** downloads GDAS analysis for a provided date.  \n",
    "**get_GDAS_data:** (convenience function) downloads GDAS analysis for a date and the entire week before it.  \n",
    "**get_latest_hysplit_analysis:** (convenience function) downloads most recent GDAS analysis.  \n",
    "**get_hysplit_appended_files:** download GFS 'appended forecast' (bridges gap between latest analysis and forecast).  \n",
    "**get_hysplit_forecast_files:** download most recent forecast for a given date, default today.  \n",
    "\n",
    "First we'll demonstrate downloading the most recent version of each data, for e.g. trajectories starting yesterday and going 3 days forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the most recent GFS forecast, analysis, and appended data (for near-future or recent-pass trajectories).\n",
    "(latest_forecast, forecast_date) = utils.get_hysplit_forecast_files()\n",
    "(latest_appended, appended_date)= utils.get_hysplit_appended_files()\n",
    "(latest_analysis, analysis_date) = utils.get_latest_hysplit_analysis()\n",
    "\n",
    "print(\"latest forecast: {} (covers 192 hours after this)\".format(forecast_date))\n",
    "print(\"latest appended: {} (covers 48 hours prior to this)\".format(appended_date))\n",
    "print(\"latest analysis: {} (covers 24 hours after this )\".format(analysis_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the dates for different model data types sometimes represent represent the last valid timestep, sometimes the first. Details are in the HYSPLIT user guide for other resolutions/data types.\n",
    "\n",
    "Next we'll fetch a week's worth of analysis from an old date, for the purposes of runnning backtrajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get HYSPLIT analysis from one particular day + week before\n",
    "date = dt.datetime(2015, 7, 7, 18, 0, 0)\n",
    "(july2015_analysis_list, analysis_date) = utils.get_GDAS_data(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Running trajectories\n",
    "\n",
    "Next we'll run some trajectories, using the HYSPLIT data we just downloaded. To see the full range of options for running HYSPLIT, either look at the docstring for hysplit_utils.write_control_file(), and read the HYSPLIT user guide. \n",
    "HYSPLIT needs to know the following parameters: trajectory start time, point(s) from which to run trajectories, list of source files on disk, hours to run, vertical motion type (level, fixed pressure, etc), initialization height, and save directory. \n",
    "\n",
    "A few things to note:  \n",
    "1) for the list of source files, they are traversed in listed order, so always place analysis first in the list, to give it priority over appended data.  \n",
    "2) always provide a list of (lat, lon) coordinates. \n",
    "3) negative hours means backtrajectories  \n",
    "4) height defaults to above ground level  \n",
    "5) write_control_file creates the HYSPLIT control file, but does not call HYSPLIT (next step). The output location for HYSPLIT is determined by a line in the control file, and so that location is returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a single trajectory forward using forecast data. Let's do 3 days, 3D, \n",
    "# starting 24 hours before our latest forecast (i.e. sometime yesterday)\n",
    "forecast_tdump = utils.write_control_file(start_time = forecast_date-dt.timedelta(days=1),\n",
    "                                          coords = [(47, -122)],\n",
    "                                          hyfile_list = [latest_analysis, latest_appended, latest_forecast],\n",
    "                                          hours = 72,\n",
    "                                          vertical_type = 0,\n",
    "                                          init_height = 4000,\n",
    "                                          tdump_prefix='demo_')\n",
    "with open('/home/disk/eos4/jkcm/Data/HYSPLIT/tdump/demo/forecast.log', 'w') as logfile:\n",
    "    utils.run_HYSPLIT(log=logfile); # this should take a few seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets run a grid of trajectories, and use one the grid-making utility functions.\n",
    "grid_coords = utils.gridder(SW=(50, 1), NW=(60, 1), NE=(60, 10), SE=(50, 10), \n",
    "                      numlats=6, numlons=6)\n",
    "historical_tdump = utils.write_control_file(start_time = analysis_date,\n",
    "                                          coords = grid_coords,\n",
    "                                          hyfile_list = july2015_analysis_list,\n",
    "                                          hours = -4*24,\n",
    "                                          vertical_type = 1,  # isobaric\n",
    "                                          init_height = 4000,\n",
    "                                          tdump_prefix='demo_')\n",
    "utils.run_HYSPLIT(); # this should take about 20 seconds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Reading and plotting trajectory output   \n",
    "Finally we'll use the two examples so far to illustrate how to read in those tdump files and plot them. You can do this by hand (if you navigate to the location on disk in e.g. forecast_tdump, you'll find a plaintext file containing trajectory data). Trajectories are read in as a pandas DataFrame. For multi-trajectory files, 'tnum' indexes the trajectory number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forecast_tdump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo for how to read trajectory data\n",
    "forecast_traj = utils.read_tdump(forecast_tdump)\n",
    "trajectory_grouped = forecast_traj.groupby('tnum')\n",
    "print(\"trajectory numbers: {}\".format(trajectory_grouped.groups.keys()))\n",
    "trajectory_1 = trajectory_grouped.get_group(1)\n",
    "print(\"trajectory columns: {}\".format(trajectory_1.columns.values))\n",
    "plt.plot(trajectory_1.index.values, trajectory_1['height'])\n",
    "plt.xlabel(\"date\")\n",
    "plt.ylabel(\"height (m)\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Included in this package a few plotting functions as well, which might be helpful. We'll demonstrate using these to visualize trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latlon_range = {'lat': (30, 80), 'lon': (-70, 20)}\n",
    "fig = utils.plot_tdump_with_heights(historical_tdump, latlon_range=latlon_range)\n",
    "fig.set_size_inches(12.5, 10.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
